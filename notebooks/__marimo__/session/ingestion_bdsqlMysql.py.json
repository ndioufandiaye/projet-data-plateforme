{
  "version": "1",
  "metadata": {
    "marimo_version": "0.20.2"
  },
  "cells": [
    {
      "id": "MJUe",
      "code_hash": "be7c6f1679eb8c7bf2fe9022db603fa7",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h1 id=\"data-plateforme-avec-pyspark-mysql-et-minio\">Data Plateforme avec PySpark, MySQL et MinIO</h1>\n<h2 id=\"architecture\">Architecture</h2>\n<div class=\"language-text codehilite\"><pre><span></span><code>MySQL (source de donn\u00e9es)\n      \u2502\n      \u25bc\nPySpark (moteur de traitement)\n      \u2502\n      \u25bc\nMinIO / S3 (Data Lake - format Parquet)\n</code></pre></div>\n<hr />\n<h2 id=\"configuration-de-lenvironnement\">Configuration de l'environnement</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "bkHC",
      "code_hash": "cccdee6f589a8acd324703ae4cc4033f",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"initialisation-de-la-session-spark\">Initialisation de la session Spark</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "SFPL",
      "code_hash": "eae3ff5c55acecb14c9856af03acbf9a",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"etape-12-ecriture-dans-minio-datalake\">\u00c9tape 1.2 \u2014 \u00c9criture dans MinIO (datalake)</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "RGSE",
      "code_hash": "a9be3d748dd085c68f5e894e001010ec",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"lecture-donnee-source-mysql-depuis-minio\">Lecture donn\u00e9e source mysql depuis MinIO</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "emfo",
      "code_hash": "0de9e94b742bb05226bafcaa7d569e88",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h1 id=\"data-plateforme-avec-pyspark-fichier-csv-et-minio\">Data Plateforme avec PySpark, fichier csv et MinIO</h1>\n<h2 id=\"architecture\">Architecture</h2>\n<div class=\"language-text codehilite\"><pre><span></span><code>Fichier csv (source de donn\u00e9es)\n      \u2502\n      \u25bc\nPySpark (moteur de traitement)\n      \u2502\n      \u25bc\nMinIO / S3 (Data Lake - format Parquet)\n</code></pre></div>\n<hr />\n<h2 id=\"configuration-de-lenvironnement\">Configuration de l'environnement</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "nWHF",
      "code_hash": "8c8a8b0b045ed592ddcbeb8913da75de",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/markdown": "<span class=\"markdown prose dark:prose-invert contents\"><h2 id=\"lecture-donnees-source-csv-depuis-minio\">Lecture donn\u00e9es source csv depuis MinIO</h2></span>"
          }
        }
      ],
      "console": []
    },
    {
      "id": "Hbol",
      "code_hash": "1d0db38904205bec4d6f6f6a1f6cec3e",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": []
    },
    {
      "id": "vblA",
      "code_hash": "68d10cef7e8279e97780ea147b7c4b2a",
      "outputs": [
        {
          "type": "data",
          "data": {
            "text/plain": ""
          }
        }
      ],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": "\u2713 Configuration charg\u00e9e\n  MySQL  : mysql:3306/warehouse\n  MinIO  : http://minio:9000\n  Spark  : local[*]\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "lEQa",
      "code_hash": "46cc4b38c4d83efad8cf612e79488197",
      "outputs": [],
      "console": [
        {
          "type": "stream",
          "name": "stdout",
          "text": ":: loading settings :: url = jar:file:/usr/local/lib/python3.11/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
          "mimetype": "text/plain"
        },
        {
          "type": "stream",
          "name": "stderr",
          "text": "Ivy Default Cache set to: /root/.ivy2/cache\nThe jars for the packages stored in: /root/.ivy2/jars\norg.apache.hadoop#hadoop-aws added as a dependency\ncom.amazonaws#aws-java-sdk-bundle added as a dependency\nmysql#mysql-connector-java added as a dependency\n:: resolving dependencies :: org.apache.spark#spark-submit-parent-96cb5f89-b106-4b1d-8ff0-8fa0e85ee79d;1.0\n\tconfs: [default]\n\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\nmysql#mysql-connector-java;8.0.33 is relocated to com.mysql#mysql-connector-j;8.0.33. Please update your dependencies.\n\tfound mysql#mysql-connector-java;8.0.33 in central\n\tfound com.mysql#mysql-connector-j;8.0.33 in central\n\tfound com.google.protobuf#protobuf-java;3.21.9 in central\ndownloading https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.3.4/hadoop-aws-3.3.4.jar ...\n\t[SUCCESSFUL ] org.apache.hadoop#hadoop-aws;3.3.4!hadoop-aws.jar (826ms)\ndownloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.12.262/aws-java-sdk-bundle-1.12.262.jar ...\n\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.12.262!aws-java-sdk-bundle.jar (89693ms)\ndownloading https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/1.0.7.Final/wildfly-openssl-1.0.7.Final.jar ...\n\t[SUCCESSFUL ] org.wildfly.openssl#wildfly-openssl;1.0.7.Final!wildfly-openssl.jar (366ms)\ndownloading https://repo1.maven.org/maven2/com/mysql/mysql-connector-j/8.0.33/mysql-connector-j-8.0.33.jar ...\n\t[SUCCESSFUL ] com.mysql#mysql-connector-j;8.0.33!mysql-connector-j.jar (1413ms)\ndownloading https://repo1.maven.org/maven2/com/google/protobuf/protobuf-java/3.21.9/protobuf-java-3.21.9.jar ...\n\t[SUCCESSFUL ] com.google.protobuf#protobuf-java;3.21.9!protobuf-java.jar(bundle) (746ms)\n:: resolution report :: resolve 29250ms :: artifacts dl 93100ms\n\t:: modules in use:\n\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n\tcom.google.protobuf#protobuf-java;3.21.9 from central in [default]\n\tcom.mysql#mysql-connector-j;8.0.33 from central in [default]\n\tmysql#mysql-connector-java;8.0.33 from central in [default]\n\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n\t---------------------------------------------------------------------\n\t|                  |            modules            ||   artifacts   |\n\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n\t---------------------------------------------------------------------\n\t|      default     |   6   |   6   |   6   |   0   ||   5   |   5   |\n\t---------------------------------------------------------------------\n:: retrieving :: org.apache.spark#spark-submit-parent-96cb5f89-b106-4b1d-8ff0-8fa0e85ee79d\n\tconfs: [default]\n\t5 artifacts copied, 0 already retrieved (279477kB/23353ms)\n26/02/27 15:08:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSetting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
          "mimetype": "text/plain"
        }
      ]
    },
    {
      "id": "PKri",
      "code_hash": "c248e8a089de928c3f49065d1bfca33c",
      "outputs": [],
      "console": []
    },
    {
      "id": "Xref",
      "code_hash": "b8d0da82ebb12935ec5fc7ac75d332ad",
      "outputs": [],
      "console": []
    },
    {
      "id": "BYtC",
      "code_hash": "70f4ab5c0c1b93bc04d88e2a32a8f64f",
      "outputs": [],
      "console": []
    },
    {
      "id": "Kclp",
      "code_hash": "59290a08790abc105ed986a22bd0c225",
      "outputs": [],
      "console": []
    },
    {
      "id": "Hstk",
      "code_hash": "1a2ff06c20f7448d0f452894da375216",
      "outputs": [],
      "console": []
    },
    {
      "id": "iLit",
      "code_hash": "ca9b38d1ed7b3947268aee776321daa8",
      "outputs": [],
      "console": []
    }
  ]
}